from cgi import test
from tkinter.messagebox import NO
import numpy as np
from sklearn import preprocessing
import random
from reference_match_rate_Robosin import Property
import math
from Lost_Action_actions import Agent_actions
import pandas as pd

class Agent():

    def __init__(self, env, marking_param, *arg):
        self.env = env
        self.actions = env.actions
        self.GOAL_REACH_EXP_VALUE = 50 # max_theta # 50
        self.lost = False
        self.test = False
        self.grid = arg[0]
        self.map = arg[1]
        self.NODELIST = arg[2]
        self.refer = Property()
        self.marking_param = marking_param
        "======================================================="
        self.decision_action = Agent_actions(self.env)
        "======================================================="
        self.Node_l = ["s", "A", "B", "C", "D", "E", "F", "O", "g", "x"]

    def policy_advance(self, state, TRIGAR, action):
        
        self.TRIGAR_advance = TRIGAR
        self.prev_action = action
        print("Prev Action : {}".format(action))

        action = self.model_advance(state)
        self.Advance_action = action

        print("Action : {}".format(action))
        print("Advance action : {}".format(self.Advance_action))

        if action == None:
            print("ERROR ü§ñ")
            return self.prev_action, self.Reverse, self.TRIGAR_advance # „Åì„ÅÆprev action „ÇÇ‰ªÆ
            
        return action, self.Reverse, self.TRIGAR_advance

    def policy_bp(self, state, TRIGAR, TRIGAR_REVERSE, COUNT):
        self.TRIGAR_bp = TRIGAR
        self.TRIGAR_REVERSE_bp = TRIGAR_REVERSE
        self.All = False
        self.Reverse = False
        self.COUNT = COUNT

        try:
            action, self.Reverse = self.model_bp(state)
            print("Action : {}".format(action))
        except:
        # except Exception as e:
        #     print('=== „Ç®„É©„ÉºÂÜÖÂÆπ ===')
        #     print('type:' + str(type(e)))
        #     print('args:' + str(e.args))
        #     print('message:' + e.message)
        #     print('eËá™Ë∫´:' + str(e))
            print("agent / policy_bp ERROR")

            "Âãï„ÅÑ„Å¶„ÅÑ„Å™„ÅÑÊôÇ„Å´Ëø∑„Å£„Åü„Å®„Åô„ÇãÂ†¥Âêà"
            # if NOT_MOVE:
            #     self.All = True
            
            # „Åì„Çå„ÅÆ„Åä„Åã„Åí„ÅßÊ≤º„Åß„ÇÇÂ∞ë„ÅóÂãï„Åë„Å¶„ÅÑ„Çã
            return random.choice(self.actions), self.Reverse, self.lost
            
        return action, self.Reverse , self.lost

    def policy_exp(self, state, TRIGAR):
        self.trigar = TRIGAR
        attribute = self.NODELIST[state.row][state.column]
        next_direction = random.choice(self.actions)
        self.All = False
        bp = False
        self.lost = False
        self.Reverse = False
        
        try:
            y_n, action, bp = self.model_exp(state)
            print("y/n:{}".format(y_n))
            print("Action : {}".format(action))
        except:
            print("„Åì„ÅÆ„Éé„Éº„Éâ„Åã„ÇâÊé¢Á¥¢„Åß„Åç„ÇãË®±ÂÆπÁØÑÂõ≤„ÅØÊé¢Á¥¢Ê∏à„Åø\nÊàª„ÇãÂ†¥ÊâÄÊ±∫ÂÆö„ÅÆ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Å∏")
            print("TRIGAR : {}".format(self.trigar))
            # self.All = True
            return self.actions[1], bp, self.All, self.trigar, self.Reverse, self.lost
        return action, bp, self.All, self.trigar, self.Reverse, self.lost

    def model_exp(self, state):

        next_diretion = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]

        y_n = False
        bp = False
        pre, Node, Arc, Arc_sum, PERMISSION = self.refer.reference()

        # ‰ªä„ÅØ„Åì„Åì„Å´ÂÖ•„Å£„Å¶bp_algorithm„Å´ÈÅ∑Áßª„Åó„Å¶„ÅÑ„Çã
        if self.NODELIST[state.row][state.column] in pre:
                print("========\nÊé¢Á¥¢ÁµÇ‰∫Ü\n========")
                self.trigar = False
                bp = True
        elif self.NODELIST[state.row][state.column] == "x":
            print("========\n‰∫§Â∑ÆÁÇπ\n========")
            self.trigar = False

        print("========\nÊé¢Á¥¢ÈñãÂßã\n========")

        exp_action = []
        for dir in next_diretion:

            print("dir:{}".format(dir))
            y_n, action = self.env.expected_move(state, dir, self.trigar, self.All, self.marking_param)
            
            if y_n:
                y_n = False
                exp_action.append(action)
                print("================================================== exp action : {}".format(exp_action))

        if exp_action:
            
            if self.NODELIST[state.row][state.column] in pre: # "x":
                print("========\n‰∫§Â∑ÆÁÇπ\n========")
                ##############
                Average_Value = self.decision_action.value(exp_action)
                ##############
                print("\n===================\nü§ñ‚ö°Ô∏è Average_Value:{}".format(Average_Value))
                print(" == ÂêÑË°åÂãïÂæå„Å´„Çπ„Éà„É¨„Çπ„ÅåÊ∏õ„Çâ„Åõ„ÇãÁ¢∫Áéá:{}".format(Average_Value))
                print(" == „Å§„Åæ„Çä„ÄÅÊñ∞„Åó„ÅÑÊÉÖÂ†±„ÅåÂæó„Çâ„Çå„ÇãÁ¢∫Áéá:{} -----> „Åì„Çå„Åå‰∏ÄÁï™ÈáçË¶Å„Éª„Éª„ÉªÊú™Êé¢Á¥¢„Åã„Å§„Åì„ÅÆÊï∞ÂÄ§„ÅåÂ§ß„Åç„ÅÑÊñπÂêë„ÅÆË°åÂãï„ÇíÈÅ∏Êäû\n===================\n".format(Average_Value))
                ##############
                action_value = self.decision_action.policy(Average_Value)
                ##############
                if action_value == self.env.actions[2]: #  LEFT:
                    NEXT = "LEFT  ‚¨ÖÔ∏è"
                    print("    At :-> {}".format(NEXT))
                if action_value == self.env.actions[3]: # RIGHT:
                    NEXT = "RIGHT ‚û°Ô∏è"
                    print("    At :-> {}".format(NEXT))  
                if action_value == self.env.actions[0]: #  UP:
                    NEXT = "UP    ‚¨ÜÔ∏è"
                    print("    At :-> {}".format(NEXT))
                if action_value == self.env.actions[1]: # DOWN:
                    NEXT = "DOWN  ‚¨áÔ∏è"
                    print("    At :-> {}".format(NEXT))

                print("ÈÅéÂéª„ÅÆ„Ç®„Éî„ÇΩ„Éº„Éâ„Åã„Çâ„ÄÅÁèæÊôÇÁÇπ„Åß„ÅØ„ÄÅü§ñ‚ö†Ô∏è At == {}„ÇíÈÅ∏Êäû„Åô„Çã".format(action_value))
                Episode_0 = self.decision_action.save_episode(action_value)
            else:
                action_value = exp_action[0]

            for x in exp_action:
                print("All exp action : {}".format(x))
            y_n = True
            return y_n, action_value, bp

        print("y/n:{}".format(y_n))

        if not bp:
            print("==========\n„Åì„Çå‰ª•‰∏äÈÄ≤„ÇÅ„Å™„ÅÑÁä∂ÊÖã\n or Ê¨°„ÅÆ„Éû„Çπ„ÅØÊé¢Á¥¢Ê∏à„Åø\n==========") # „Å©„ÅÆÈÅ∏ÊäûËÇ¢„ÇÇ y_n = False
            self.lost = True
        else:
            self.All = True

        print("==========\nËø∑„Å£„ÅüÁä∂ÊÖã\n==========") # „Å©„ÅÆÈÅ∏ÊäûËÇ¢„ÇÇ y_n = False
        print("= ÁèæÂú®Âú∞„Åã„Çâ„Ç¥„Éº„É´„Å´Ëøé„Åà„ÇãÈÅ∏ÊäûËÇ¢„ÅØ„Å™„ÅÑ\n")

    def model_advance(self, state):

        next_diretion = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]

        pre, Node, Arc, Arc_sum, PERMISSION = self.refer.reference()
        if self.NODELIST[state.row][state.column] in pre:
            print("„É©„É≥„ÉÄ„É†„Å´Ê±∫ÂÆö")
            next_diretion = self.advance_direction_decision(next_diretion)
        else:
            next_diretion = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
        # advance„ÅÆË°åÂãï„ÅÆÂÑ™ÂÖàÂ∫¶„Çí„ÅÇ„Çâ„Åã„Åò„ÇÅË®≠ÂÆö

        if self.NODELIST[state.row][state.column] == "x":
            print("„É©„É≥„ÉÄ„É†„Å´Ê±∫ÂÆö")
            next_diretion = self.advance_direction_decision(next_diretion)
        print("next dir : {}".format(next_diretion))

        y_n = False
        self.All = False
        self.Reverse = False

        if self.NODELIST[state.row][state.column] == "x":
            print("========\n‰∫§Â∑ÆÁÇπ\n========")
            self.TRIGAR_advance = False

        print("========\nAdvanceÈñãÂßã\n========")
        if not self.TRIGAR_advance:
            for dir in next_diretion:

                print("dir:{}".format(dir))
                y_n, action = self.env.expected_move(state, dir, self.TRIGAR_advance, self.All, self.marking_param)

                if y_n:
                    self.prev_action = action
                    return action
                print("y/n:{}".format(y_n))
        print("==========\nËø∑„Å£„Åü„ÄêË®±ÂÆπ„ÇíË∂Ö„Åà„Çã„ÄëÁä∂ÊÖã\n==========") # „Å©„ÅÆÈÅ∏ÊäûËÇ¢„ÇÇ y_n = False
        print("= „Åì„Çå‰ª•‰∏äÂÖà„Å´ÁèæÂú®Âú∞„Åã„Çâ„Ç¥„Éº„É´„Å´Ëøé„Åà„ÇãÈÅ∏ÊäûËÇ¢„ÅØ„Å™„ÅÑ\n= ‰∏ÄÊó¶‰ΩìÂà∂„ÇíÊï¥„Åà„Çã\n= Êàª„Çã")
        print("\n „Å®„ÅÑ„ÅÜ„Çà„Çä„ÅØ„Çπ„Éà„É¨„Çπ„ÅåÊ∫ú„Åæ„ÇäÂàá„ÇãÂâç„Å´„Åì„Çå‰ª•‰∏äÈÄ≤„ÇÅ„Å™„Åè„Å™„Å£„Å¶„Ç®„É©„Éº„ÅåÂá∫„Çã")
        self.TRIGAR_advance = True

    def model_bp(self, state):

        pre, Node, Arc, Arc_sum, PERMISSION = self.refer.reference()

        print("========\nBACK ÈñãÂßã\n========")
        print("TRIGAR : {}".format(self.TRIGAR_bp))
        print("REVERSE : {}".format(self.TRIGAR_REVERSE_bp))
        
        if self.TRIGAR_REVERSE_bp:
            self.Reverse = True
            next_diretion = self.next_direction_decision("reverse")
            for dir in next_diretion:
                print("\ndir:{}".format(dir))
                y_n, action = self.env.expected_move_return_reverse(state, dir, self.TRIGAR_REVERSE_bp, self.Reverse)

                if y_n:
                    self.lost = False
                    return action, self.Reverse
                print("y/n:{}".format(y_n))
            print("TRIGAR REVERSE ‚ö°Ô∏èüèÅ")

        if self.TRIGAR_bp:
            next_diretion = self.next_direction_decision("trigar")

            for dir in next_diretion:
                print("\ndir:{}".format(dir))
                y_n, action = self.env.expected_move_return(state, dir, self.TRIGAR_bp, self.All)

                if y_n:
                    self.lost = False
                    return action, self.Reverse
                print("y/n:{}".format(y_n))

            if self.lost:
                print("==========\n„Åì„Çå‰ª•‰∏äÊàª„Çå„Å™„ÅÑÁä∂ÊÖã\n or Ê¨°„ÅÆ„Éû„Çπ„ÅØ‰ª•ÂâçÊàª„Å£„ÅüÂ†¥ÊâÄ\n==========") # „Å©„ÅÆÈÅ∏ÊäûËÇ¢„ÇÇ y_n = False
                for dir in next_diretion:
                    print("\ndir:{}".format(dir))
                    y_n, action = self.env.expected_not_move(state, dir, self.trigar, self.All)

                    if y_n:
                        return action, self.Reverse
                    print("y/n:{}".format(y_n))

        print("==========\nÊàª„ÇäÁµÇ„Çè„Å£„ÅüÁä∂ÊÖã\n==========") # „Å©„ÅÆÈÅ∏ÊäûËÇ¢„ÇÇ y_n = False
        print("= ÁèæÂú®Âú∞„Åã„ÇâÊ¨°„Å´„Ç¥„Éº„É´„Å´Ëøé„Åà„ÇãÈÅ∏ÊäûËÇ¢„ÇíÈÅ∏„Å∂„ÄêÊú™Êé¢Á¥¢ÊñπÂêë„Äë\n")
        self.lost = True

    def back_position(self, BPLIST, w, Arc, Cost): # change
        
        "----------------------------------------------------------------------"
        "== stress„ÅÆÂ∞è„Åï„Åï„ÅßÊàª„Çã„Éé„Éº„Éâ„ÇíÊ±∫„ÇÅ„ÇãÂ†¥Âêà =="
        Move_Cost = [round(Cost[x],2) for x in range(len(Cost))]
        "----------------------------------------------------------------------"  
        "----------------------------------------------------------------------"
        # Ê≠£Ë¶èÂåñ„Å´„Åô„Çã„Å®0, 1„ÅåÂá∫„Å¶„Åó„Åæ„ÅÜ„ÅÆ„Åß„ÄÅstress√ócost „Åß0„Å´„Å™„Çä„ÇÑ„Åô„Åè„ÄÅ„Åù„Åì„Å´Êàª„Çã„Åì„Å®„ÅåÂ§ö„Åè„Å™„Å£„Å¶„Åó„Åæ„ÅÜ
        "Ê≠£Ë¶èÂåñ„ÅÆÁÇ∫„ÅÆÂá¶ÁêÜ"  
        # w = np.round(preprocessing.minmax_scale(w), 3)
        # Arc = np.round(preprocessing.minmax_scale(Arc), 3)
        # Move_Cost = np.round(preprocessing.minmax_scale(Move_Cost), 3)
        "----------------------------------------------------------------------"
        print("üìê Ê≠£Ë¶èÂåñ WEIGHT : {}, Move_Cost : {}".format(w, Move_Cost))
        print(type(w), type(Move_Cost))
        "-> „Å©„Å£„Å°„ÇÇlist"

        # Arc = [0, 0]„ÅÆÊôÇ,Arc = [1, 1]„Å´Â§âÊõ¥
        if all(elem  == 0 for elem in Move_Cost):
            Move_Cost = [1 for elem in Move_Cost]
            print("   Arc = [0, 0]„ÅÆÊôÇ, Move_Cost : {}".format(Move_Cost))
        if all(elem  == 0 for elem in w):
            w = [1 for elem in w]
            print("   WEIGHT = [0, 0]„ÅÆÊôÇ, WEIGHT : {}".format(w))

        WEIGHT_CROSS = [round(x*y, 3) for x,y in zip(w,Move_Cost)]
        "->ÊîπËâØ„Åô„ÇãÂøÖË¶Å„ÅÇ„Çä"
        "OBS„ÅÆ„ÅøÂâäÈô§„Åï„Çå„Å¶„ÅÑ„Çã"

        print("‚ö°Ô∏è WEIGHT CROSS:{}".format(WEIGHT_CROSS))

        try:
            if all(elem  == 0 for elem in WEIGHT_CROSS):
                print("WEIGHT CROSS„ÅØÂÖ®ÈÉ®0„Åß„Åô„ÄÇ")
                print("Arc type : {}".format(type(Arc)))
                near_index = Arc.index(min(Arc))
                print("Arc:{}, index:{}".format(Arc, near_index))
                WEIGHT_CROSS[near_index] = 1
                print("‚ö°Ô∏è WEIGHT CROSS:{}".format(WEIGHT_CROSS))
        except:
            pass

        print(type(WEIGHT_CROSS))

        
        "„Çπ„Éà„É¨„Çπ„ÅÆ„Åø„ÅßÊàª„ÇãÂ†¥ÊâÄÊ±∫ÂÆö„Åô„ÇãÂ†¥Âêà"
        # try:
        #     w = w.tolist()
        # except:
        #     pass
        # next_position = BPLIST[w.index(min(w))]
        "----------------------------------------------------------------------"
        "„Çπ„Éà„É¨„Çπ+ÁßªÂãï„Ç≥„Çπ„Éà„ÅßÊàª„ÇãÂ†¥ÊâÄ„ÇíÊ±∫ÂÆö„Åô„ÇãÂ†¥Âêà"
        next_position = BPLIST[WEIGHT_CROSS.index(min(WEIGHT_CROSS))] # stress + cost
        "----------------------------------------------------------------------"
        # next_position = pd.Series(next_position, index=self.Node_l)

        return next_position

    def back_end(self, BPLIST, next_position, w, OBS, test_index, move_cost_result):

        w = BPLIST
        print("ü•å WEIGHT(remove):{}".format(w))
        try:
            OBS.pop(test_index)
        except:
            OBS = OBS.tolist()
            OBS.pop(test_index)
        print("ü•å OBS(remove):{}".format(OBS))

        return BPLIST, w, OBS

    def next_direction_decision(self, trigar__or__reverse):
        if self.Advance_action == self.actions[0]: # Action.UP:
            self.BP_action = self.actions[1] # [0]
            next_diretion_trigar = [(self.actions[1]), (self.actions[0]), (self.actions[2]), (self.actions[3])]
            next_diretion_trigar_reverse = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
        elif self.Advance_action == self.actions[1]: # Action.DOWN:
            self.BP_action = self.actions[0] # [1]
            next_diretion_trigar = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
            next_diretion_trigar_reverse = [(self.actions[1]), (self.actions[0]), (self.actions[2]), (self.actions[3])]
        elif self.Advance_action == self.actions[2]: # Action.LEFT:
            self.BP_action = self.actions[3] # [2]
            next_diretion_trigar = [(self.actions[3]), (self.actions[2]), (self.actions[0]), (self.actions[1])]
            next_diretion_trigar_reverse = [(self.actions[2]), (self.actions[3]), (self.actions[0]), (self.actions[1])]
        elif self.Advance_action == self.actions[3]: # Action.RIGHT:
            self.BP_action = self.actions[2] # [3]
            next_diretion_trigar = [(self.actions[2]), (self.actions[3]), (self.actions[0]), (self.actions[1])]
            next_diretion_trigar_reverse = [(self.actions[3]), (self.actions[2]), (self.actions[0]), (self.actions[1])]
        else:
            next_diretion_trigar, next_diretion_trigar_reverse = self.next_direction_decision_prev_action()

        if trigar__or__reverse == "trigar":
            print("tigar__or__reverse : {}".format(trigar__or__reverse))
            return next_diretion_trigar
        if trigar__or__reverse == "reverse":
            print("tigar__or__reverse : {}".format(trigar__or__reverse))
            return next_diretion_trigar_reverse

    def next_direction_decision_prev_action(self):
        if self.prev_action == self.actions[0]: # Action.UP:
            self.BP_action = self.actions[1]
            next_diretion_trigar = [(self.actions[1]), (self.actions[0]), (self.actions[2]), (self.actions[3])]
            next_diretion_trigar_reverse = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
        elif self.prev_action == self.actions[1]: # Action.DOWN:
            self.BP_action = self.actions[0]
            next_diretion_trigar = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
            next_diretion_trigar_reverse = [(self.actions[1]), (self.actions[0]), (self.actions[2]), (self.actions[3])]
        elif self.prev_action == self.actions[2]: # Action.LEFT:
            self.BP_action = self.actions[3]
            next_diretion_trigar = [(self.actions[3]), (self.actions[2]), (self.actions[0]), (self.actions[1])]
            next_diretion_trigar_reverse = [(self.actions[2]), (self.actions[3]), (self.actions[0]), (self.actions[1])]
        elif self.prev_action == self.actions[3]: # Action.RIGHT:
            self.BP_action = self.actions[2]
            next_diretion_trigar = [(self.actions[2]), (self.actions[3]), (self.actions[0]), (self.actions[1])]
            next_diretion_trigar_reverse = [(self.actions[3]), (self.actions[2]), (self.actions[0]), (self.actions[1])]

        return next_diretion_trigar, next_diretion_trigar_reverse

    def advance_direction_decision(self, dir):

        test = random.sample(dir, len(dir))
        print("test dir : {}, dir : {}".format(test, dir))
        return test # random.shuffle(dir)
        #  [<Action.RIGHT: -2>, <Action.DOWN: -1>, <Action.UP: 1>, <Action.LEFT: 2>]
